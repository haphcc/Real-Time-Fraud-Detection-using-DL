{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b08039",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82b08039",
    "outputId": "fcc5ff26-a8d6-46e3-b473-61749cbfbaea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Tải dữ liệu từ file CSV\n",
    "duong_dan_file = 'C:\\\\Users\\\\phuoc\\\\Downloads\\\\NCKH\\\\financial_fraud_detection_dataset.csv'\n",
    "try:\n",
    "    df = pd.read_csv(duong_dan_file)\n",
    "    print(\"Dữ liệu đã được tải thành công.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file tại đường dẫn {duong_dan_file}. Vui lòng kiểm tra lại đường dẫn.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10278668",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "10278668",
    "outputId": "fefbbd19-079b-4b5b-df73-c4bbbebdf3e4"
   },
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"\\n5 dòng đầu tiên của dữ liệu:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nThông tin về các cột và kiểu dữ liệu:\")\n",
    "    display(df.info())\n",
    "\n",
    "    print(\"\\nThống kê mô tả dữ liệu:\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07241bdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07241bdf",
    "outputId": "25998a57-ded2-4fb1-f610-e5a2f2b0667f"
   },
   "outputs": [],
   "source": [
    "print(\"Bắt đầu xử lý dữ liệu...\")\n",
    "\n",
    "# Tải lại dữ liệu để đảm bảo chúng ta bắt đầu với các cột gốc\n",
    "duong_dan_file = 'C:\\\\Users\\\\phuoc\\\\Downloads\\\\Tai lieu thuc hanh Python\\\\IS23A AMD Lab\\\\Homework\\\\creditcard.csv'\n",
    "try:\n",
    "    df_processed = pd.read_csv(duong_dan_file)\n",
    "    print(\"Dữ liệu đã được tải lại thành công.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file tại đường dẫn {duong_dan_file}. Vui lòng kiểm tra lại đường dẫn.\")\n",
    "    df_processed = None\n",
    "\n",
    "if df_processed is not None:\n",
    "    # Loại bỏ cột 'Time'\n",
    "    df_processed = df_processed.drop('Time', axis=1)\n",
    "    print(\"Cột 'Time' đã được loại bỏ.\")\n",
    "\n",
    "    # Loại bỏ các hàng chứa giá trị NaN\n",
    "    df_processed.dropna(inplace=True)\n",
    "    print(\"Đã loại bỏ các hàng chứa giá trị NaN.\")\n",
    "\n",
    "    # Chuẩn hóa cột 'Amount'\n",
    "    df_processed['NormalizedAmount'] = StandardScaler().fit_transform(df_processed['Amount'].values.reshape(-1, 1))\n",
    "    print(\"Cột 'Amount' đã được chuẩn hóa thành 'NormalizedAmount'.\")\n",
    "\n",
    "    # Loại bỏ cột 'Amount' gốc\n",
    "    df_processed = df_processed.drop('Amount', axis=1)\n",
    "    print(\"Cột 'Amount' gốc đã được loại bỏ.\")\n",
    "\n",
    "    # Chia dữ liệu\n",
    "    print(\"Bắt đầu chia dữ liệu thành tập huấn luyện và kiểm tra...\")\n",
    "    X = df_processed.drop('Class', axis=1).values\n",
    "    y = df_processed['Class'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"Dữ liệu đã được chia thành tập huấn luyện và kiểm tra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cb6c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f00cb6c1",
    "outputId": "d8fa71da-195f-4941-9bc1-b323e1650686"
   },
   "outputs": [],
   "source": [
    "# Chuyển đổi dữ liệu huấn luyện thành tensor PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(\"Dữ liệu huấn luyện đã được chuyển đổi thành tensor.\")\n",
    "\n",
    "# Định nghĩa lớp dataset tùy chỉnh\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        print(\"CustomDataset đã được khởi tạo.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "print(\"Lớp CustomDataset đã được định nghĩa.\")\n",
    "\n",
    "# Định nghĩa mô hình ODIN\n",
    "class ODINModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ODINModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        # Loại bỏ hàm sigmoid tại đây\n",
    "        print(\"Mô hình ODIN đã được khởi tạo.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "print(\"Lớp ODINModel đã được định nghĩa.\")\n",
    "\n",
    "# Khởi tạo mô hình, hàm mất mát và trình tối ưu hóa\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "model = ODINModel(input_size, hidden_size, output_size)\n",
    "# Sử dụng BCEWithLogitsLoss, hàm này ổn định hơn\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"Mô hình, loss function và optimizer đã được khởi tạo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7604de2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7604de2",
    "outputId": "ad98a5fb-7bc4-413e-d9c7-1f72a6fd672b"
   },
   "outputs": [],
   "source": [
    "# Vòng lặp huấn luyện\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "\n",
    "# Tạo dataset và dataloader\n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "print(\"Dataset huấn luyện đã được tạo.\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(\"DataLoader huấn luyện đã được khởi tạo.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} bắt đầu...\")\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Lấy logits từ mô hình\n",
    "        outputs = model(inputs)\n",
    "        # Sử dụng BCEWithLogitsLoss, hàm này yêu cầu logits\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "print(\"Huấn luyện mô hình hoàn tất.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b7583",
   "metadata": {
    "id": "525b7583"
   },
   "source": [
    "### Giải thích codeblock 8: Huấn luyện mô hình\n",
    "\n",
    "#### **Mục tiêu:**\n",
    "- Huấn luyện mô hình trên tập dữ liệu huấn luyện.\n",
    "\n",
    "#### **Quy trình:**\n",
    "1. **Khởi tạo tham số huấn luyện:**\n",
    "   - `num_epochs`: Số lần lặp qua toàn bộ dữ liệu huấn luyện.\n",
    "   - `batch_size`: Kích thước của mỗi batch dữ liệu được sử dụng trong một lần huấn luyện.\n",
    "\n",
    "2. **Tạo dataset và DataLoader:**\n",
    "   - `CustomDataset`: Lớp dataset tùy chỉnh để quản lý dữ liệu huấn luyện.\n",
    "   - `DataLoader`: Chia dữ liệu thành các batch và cung cấp cơ chế lặp qua dữ liệu.\n",
    "\n",
    "3. **Vòng lặp huấn luyện:**\n",
    "   - Tính toán đầu ra của mô hình.\n",
    "   - Tính toán hàm mất mát (loss).\n",
    "   - Lan truyền ngược (backpropagation) để cập nhật trọng số mô hình.\n",
    "\n",
    "4. **In thông tin:**\n",
    "   - Hiển thị tiến trình huấn luyện (epoch, loss trung bình).\n",
    "\n",
    "#### **Kết quả:**\n",
    "- Mô hình được huấn luyện xong, sẵn sàng để đánh giá.\n",
    "\n",
    "#### **Tóm tắt:**\n",
    "- **Mục tiêu:** Tập trung vào huấn luyện mô hình.\n",
    "- **Kỹ thuật sử dụng:** Không sử dụng kỹ thuật ODIN, chỉ huấn luyện cơ bản.\n",
    "- **Kết quả:** Mô hình được huấn luyện xong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3d1f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "1ad3d1f5",
    "outputId": "2f64f823-b3f5-4eb8-f65e-2f90327a96f4"
   },
   "outputs": [],
   "source": [
    "# Đánh giá mô hình\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "model.eval()\n",
    "# Lấy logits từ tập kiểm tra\n",
    "logits = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "# Áp dụng hàm sigmoid để chuyển đổi logits thành xác suất\n",
    "y_scores = torch.sigmoid(logits).detach().numpy()\n",
    "# Chuyển đổi xác suất thành dự đoán nhị phân\n",
    "y_pred = (y_scores > 0.5).astype(int)  # Chuyển đổi xác suất thành dự đoán nhị phân\n",
    "\n",
    "# Tính toán đường cong ROC và AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường cong ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Đường cong ROC (diện tích = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Tỷ lệ dương tính giả')\n",
    "plt.ylabel('Tỷ lệ dương tính thật')\n",
    "plt.title('Đường cong ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Diện tích dưới đường cong (AUC): {roc_auc:.2f}\")\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Ma trận nhầm lẫn:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Báo cáo phân loại\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nBáo cáo phân loại:\")\n",
    "print(class_report)\n",
    "\n",
    "# Độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nĐộ chính xác: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd300f",
   "metadata": {
    "id": "1ccd300f"
   },
   "source": [
    "### Codeblock 9: Đánh giá mô hình với ODIN\n",
    "\n",
    "#### **Mục tiêu:**\n",
    "- Đánh giá hiệu suất của mô hình trên tập kiểm tra bằng cách sử dụng các kỹ thuật ODIN.\n",
    "\n",
    "#### **Quy trình:**\n",
    "1. **Thêm nhiễu đầu vào:**\n",
    "   - Sử dụng gradient để tạo nhiễu (input perturbation).\n",
    "2. **Áp dụng nhiệt độ scaling:**\n",
    "   - Điều chỉnh logits bằng siêu tham số nhiệt độ.\n",
    "3. **Tính toán xác suất:**\n",
    "   - Chuyển đổi logits thành xác suất dự đoán.\n",
    "4. **Đánh giá hiệu suất:**\n",
    "   - Tính các chỉ số như ROC, AUC, ma trận nhầm lẫn, và báo cáo phân loại.\n",
    "   - Vẽ biểu đồ ROC để trực quan hóa hiệu suất.\n",
    "\n",
    "#### **Kết quả:**\n",
    "- Các chỉ số đánh giá hiệu suất của mô hình với kỹ thuật ODIN được tính toán và trực quan hóa.\n",
    "\n",
    "#### **Điểm khác biệt chính:**\n",
    "- **Mục tiêu:**\n",
    "  - Codeblock 9 tập trung vào đánh giá mô hình với kỹ thuật ODIN.\n",
    "- **Kỹ thuật sử dụng:**\n",
    "  - Sử dụng input perturbation và temperature scaling.\n",
    "- **Kết quả:**\n",
    "  - Hiệu suất mô hình được đánh giá với các chỉ số và biểu đồ ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d59bf2",
   "metadata": {},
   "source": [
    "### Tại sao sử dụng BCEWithLogitsLoss và không cần hàm sigmoid ở lớp cuối cùng?\n",
    "\n",
    "#### **Giới thiệu về BCEWithLogitsLoss:**\n",
    "`BCEWithLogitsLoss` là một hàm mất mát đặc biệt được thiết kế cho các bài toán phân loại nhị phân. Điểm nổi bật của hàm này là:\n",
    "\n",
    "1. **Chuyển đổi logits thành xác suất:**\n",
    "   - Tự động áp dụng hàm sigmoid để chuyển đổi đầu ra (logits) của mô hình thành xác suất.\n",
    "2. **Tính toán Binary Cross-Entropy:**\n",
    "   - Sử dụng xác suất đã chuyển đổi để tính toán hàm mất mát.\n",
    "\n",
    "#### **Vì sao không cần hàm sigmoid ở lớp cuối cùng?**\n",
    "- Trong mô hình `ODINModel`, lớp cuối cùng (`fc2`) không sử dụng hàm sigmoid. Điều này là do `BCEWithLogitsLoss` đã bao gồm bước áp dụng sigmoid nội bộ.\n",
    "- Nếu thêm sigmoid vào lớp cuối cùng, sẽ dẫn đến việc áp dụng sigmoid hai lần, gây ra:\n",
    "  - **Lỗi tính toán.**\n",
    "  - **Giảm độ chính xác của mô hình.**\n",
    "\n",
    "#### **Lợi ích của việc không sử dụng sigmoid ở lớp cuối cùng:**\n",
    "1. **Ổn định số học:**\n",
    "   - Việc tính toán sigmoid và cross-entropy trong một bước giúp giảm thiểu các vấn đề về số học (như tràn số hoặc mất mát độ chính xác).\n",
    "2. **Hiệu suất tốt hơn:**\n",
    "   - Tránh tính toán sigmoid thủ công giúp tăng hiệu suất và đơn giản hóa mô hình.\n",
    "\n",
    "#### **Tóm lại:**\n",
    "- Mô hình không sử dụng hàm sigmoid ở lớp cuối cùng vì `BCEWithLogitsLoss` đã xử lý bước này.\n",
    "- Khi cần xác suất đầu ra (như trong đánh giá hoặc dự đoán), bạn có thể áp dụng hàm sigmoid thủ công lên logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3db3dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "8b3db3dc",
    "outputId": "e98d90fb-cf97-4736-927c-673f5b6f5d84"
   },
   "outputs": [],
   "source": [
    "# Các sửa đổi cụ thể cho phương pháp ODIN\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Hàm áp dụng nhiệt độ scaling\n",
    "def apply_temperature_scaling(logits, temperature):\n",
    "    # Chia logits cho giá trị nhiệt độ để điều chỉnh\n",
    "    return logits / temperature\n",
    "\n",
    "# Hàm thêm nhiễu đầu vào\n",
    "def add_input_perturbation(model, inputs, epsilon, temperature):\n",
    "    # Đặt đầu vào thành biến có thể tính gradient\n",
    "    inputs = Variable(inputs, requires_grad=True)\n",
    "    # Tính toán logits từ mô hình\n",
    "    logits = model(inputs)\n",
    "    # Áp dụng nhiệt độ scaling cho logits\n",
    "    scaled_logits = apply_temperature_scaling(logits, temperature)\n",
    "    dummy_loss = torch.sum(logits)\n",
    "    # Reset gradient của mô hình\n",
    "    model.zero_grad()\n",
    "    # Tính gradient của dummy loss đối với đầu vào\n",
    "    dummy_loss.backward()\n",
    "    gradient = inputs.grad.data\n",
    "    # Thêm nhiễu vào đầu vào dựa trên dấu của gradient\n",
    "    perturbed_inputs = inputs + epsilon * gradient.sign()\n",
    "    return perturbed_inputs\n",
    "\n",
    "\n",
    "# Đánh giá mô hình với các sửa đổi ODIN\n",
    "temperature = 1000  # Siêu tham số cho nhiệt độ scaling\n",
    "epsilon = 0.002  # Siêu tham số cho nhiễu đầu vào\n",
    "model.eval()\n",
    "# Thêm nhiễu vào tập kiểm tra\n",
    "def add_input_perturbation_odin(model, inputs, epsilon):\n",
    "    # Đặt đầu vào thành biến có thể tính gradient\n",
    "    inputs = Variable(inputs, requires_grad=True)\n",
    "    # Tính toán logits từ mô hình\n",
    "    logits = model(inputs)\n",
    "    dummy_loss = torch.sum(logits) # Tối đa hóa logit\n",
    "    # Reset gradient của mô hình\n",
    "    model.zero_grad()\n",
    "    # Tính gradient của dummy loss đối với đầu vào\n",
    "    dummy_loss.backward()\n",
    "    gradient = inputs.grad.data\n",
    "    # Thêm nhiễu vào đầu vào dựa trên dấu của gradient\n",
    "    perturbed_inputs = inputs + epsilon * gradient.sign()\n",
    "    return perturbed_inputs\n",
    "\n",
    "\n",
    "# Đánh giá với ODIN\n",
    "temperature = 1000  # Siêu tham số cho nhiệt độ scaling\n",
    "epsilon = 0.002  # Siêu tham số cho nhiễu đầu vào\n",
    "\n",
    "# Tính toán logits cho dữ liệu kiểm tra gốc\n",
    "original_logits = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "\n",
    "# Thêm nhiễu vào dữ liệu kiểm tra gốc\n",
    "perturbed_X_test_odin = add_input_perturbation_odin(model, torch.tensor(X_test, dtype=torch.float32), epsilon)\n",
    "\n",
    "# Tính toán logits cho dữ liệu đã thêm nhiễu\n",
    "perturbed_logits = model(perturbed_X_test_odin)\n",
    "\n",
    "# Áp dụng nhiệt độ scaling cho logits của dữ liệu đã thêm nhiễu\n",
    "scaled_perturbed_logits = apply_temperature_scaling(perturbed_logits, temperature)\n",
    "\n",
    "# Chuyển đổi logits đã được scale thành xác suất (điểm ODIN)\n",
    "odin_scores = torch.sigmoid(scaled_perturbed_logits).detach().numpy()\n",
    "\n",
    "# Đối với các chỉ số đánh giá như ROC và AUC, chúng ta sử dụng điểm ODIN.\n",
    "y_scores = odin_scores\n",
    "\n",
    "# Chuyển đổi điểm ODIN thành dự đoán nhị phân (sử dụng ngưỡng, ví dụ: 0.5)\n",
    "y_pred = (y_scores > 0.5).astype(int)\n",
    "\n",
    "# Tính toán đường cong ROC và AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường cong ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve with ODIN (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Tỷ lệ dương tính giả')\n",
    "plt.ylabel('Tỷ lệ dương tính thật')\n",
    "plt.title('Đường cong ROC với ODIN')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC with ODIN: {roc_auc:.2f}\")\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Ma trận nhầm lẫn với ODIN:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Báo cáo phân loại\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nBáo cáo phân loại với ODIN:\")\n",
    "print(class_report)\n",
    "\n",
    "# Độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nĐộ chính xác với ODIN: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
